{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4054b22-5589-40b8-9b25-7a903d5c2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "### Author: Phinehas Lampman\n",
    "### \n",
    "### Email: plampman@uidaho.edu\n",
    "### \n",
    "### Purpose: Algorithm for generating spread direction lines between two fire front observations\n",
    "###############################################################################################################\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString\n",
    "import itertools\n",
    "\n",
    "\n",
    "def calculate_azimuths(geometry_array):\n",
    "    \"\"\"\n",
    "    Helper function for process_spread_lines() function below\n",
    "    \n",
    "    Extract coordinates from geometries and calculate azimuth for both line directions (trailing to leading and leading to trailing).\n",
    "    \n",
    "    Parameters:\n",
    "    geometry_array: Array of LineString geometries passed from process_spread_lines() function below\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary containing all azimuth calculations and coordinate data for both directions (trailing and leading)\n",
    "    \"\"\"\n",
    "    # Extract coordinates\n",
    "    start_coords = np.array([line.coords[0] for line in geometry_array])\n",
    "    end_coords = np.array([line.coords[-1] for line in geometry_array])\n",
    "    \n",
    "    ax, ay = start_coords[:, 0], start_coords[:, 1]\n",
    "    bx, by = end_coords[:, 0], end_coords[:, 1]\n",
    "    \n",
    "    # Calculate raw direction angles for both directions\n",
    "    degrees_trailing = np.rad2deg(np.arctan2(by - ay, bx - ax))\n",
    "    degrees_leading = np.rad2deg(np.arctan2(ay - by, ax - bx))\n",
    "    \n",
    "    # Convert to standard azimuth (0-360 degrees) for both directions\n",
    "    conditions = [\n",
    "        (degrees_trailing < 90),\n",
    "        (degrees_trailing > 90),\n",
    "        ((degrees_trailing > 0) & (degrees_trailing <= 90)),\n",
    "        (degrees_trailing == 0)\n",
    "    ]\n",
    "    \n",
    "    choice = [\n",
    "        (90 - degrees_trailing),\n",
    "        (360 - degrees_trailing + 90),\n",
    "        (90 - degrees_trailing),\n",
    "        0\n",
    "    ]\n",
    "    \n",
    "    spread_azimuth_trailing = np.select(conditions, choice, np.nan)\n",
    "    \n",
    "    conditions = [\n",
    "        (degrees_leading < 90),\n",
    "        (degrees_leading > 90),\n",
    "        ((degrees_leading > 0) & (degrees_leading <= 90)),\n",
    "        (degrees_leading == 0)\n",
    "    ]\n",
    "    \n",
    "    choice = [\n",
    "        (90 - degrees_leading),\n",
    "        (360 - degrees_leading + 90),\n",
    "        (90 - degrees_leading),\n",
    "        0\n",
    "    ]\n",
    "    \n",
    "    spread_azimuth_leading = np.select(conditions, choice, np.nan)\n",
    "    \n",
    "    # Calculate normalized azimuth values (-180 to 180) for both directions\n",
    "    spread_az180_trailing = np.where(spread_azimuth_trailing > 180, spread_azimuth_trailing - 360, spread_azimuth_trailing)\n",
    "    spread_az180_leading = np.where(spread_azimuth_leading > 180, spread_azimuth_leading - 360, spread_azimuth_leading)\n",
    "    \n",
    "    result = {\n",
    "        'start_coords': start_coords,\n",
    "        'end_coords': end_coords,\n",
    "        'ax': ax, \n",
    "        'ay': ay,\n",
    "        'bx': bx, \n",
    "        'by': by,\n",
    "        'spread_azimuth_trailing': spread_azimuth_trailing,\n",
    "        'spread_az180_trailing': spread_az180_trailing,\n",
    "        'spread_azimuth_leading': spread_azimuth_leading,\n",
    "        'spread_az180_leading': spread_az180_leading\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def process_spread_lines(points_df1, points_df2, front1_line, front2_line, output_path=None):\n",
    "    \"\"\"\n",
    "    Create spread lines between two sets of points (front1 and front2 points) in both directions.\n",
    "    \n",
    "    Parameters:\n",
    "    points_df1: First GeoDataFrame with point geometries (must have 'angle' column)\n",
    "    points_df2: Second GeoDataFrame with point geometries (must have 'angle' column)\n",
    "    QGIS \"points along geometry\" tool outputs an \"angle\" column in the correct manner\n",
    "    -> angle (azimuth) of fire front line where the point is\n",
    "    \n",
    "    front1_line: LineString or MultiLineString representing the front1 (trailing front) line\n",
    "    front2_line: LineString or MultiLineString representing the front2 (leading front) line\n",
    "    output_path: Where to save the resulting combined GeoDataFrame\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary containing two GeoDataFrames: 'trailing' and 'leading' spread lines\n",
    "\n",
    "    Output: if output_path is provided it will save a file with trailing and leading spread lines (concatenated)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify required inputs exist\n",
    "    if 'angle' not in points_df1.columns:\n",
    "        raise ValueError(\"'angle' column not found in points_df1\")\n",
    "    if 'angle2' not in points_df2.columns:\n",
    "        raise ValueError(\"'angle2' column not found in points_df2\")\n",
    "    if front1_line is None:\n",
    "        raise ValueError(\"front1_line is required but was not provided\")\n",
    "    if front2_line is None:\n",
    "        raise ValueError(\"front2_line is required but was not provided\")\n",
    "    \n",
    "    # Unify geometries if they're collections\n",
    "    from shapely.ops import unary_union\n",
    "    if hasattr(front1_line, '__iter__') and not hasattr(front1_line, 'geom_type'):\n",
    "        front1_line = unary_union(list(front1_line))\n",
    "    if hasattr(front2_line, '__iter__') and not hasattr(front2_line, 'geom_type'):\n",
    "        front2_line = unary_union(list(front2_line))\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Process trailing direction (front1 to front2)\n",
    "    print('Processing trailing front to leading front spread lines...')\n",
    "    \n",
    "    # Get point geometries\n",
    "    geom1 = points_df1.geometry.values\n",
    "    geom2 = points_df2.geometry.values\n",
    "    \n",
    "    # Create lines between all combinations of points (direction from points1 to points2)\n",
    "    geom = [LineString([p1, p2]) for p1, p2 in itertools.product(geom1, geom2)]\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    trailing_result = gpd.GeoDataFrame({'geometry': geom}, crs=\"EPSG:26914\")\n",
    "    trailing_result['length_m'] = trailing_result.length\n",
    "    trailing_result['direction'] = \"trailing\"  # Add direction identifier\n",
    "    print(f'Created {len(trailing_result)} trailing lines')\n",
    "    \n",
    "    # Prepare front1 join dataframe\n",
    "    front1_join = points_df1.copy()\n",
    "    front1_join['xy_1'] = [tuple(p.coords[0]) for p in front1_join.geometry]\n",
    "    front1_join['Pt_ID1'] = np.arange(len(front1_join))\n",
    "    front1_join = front1_join[['xy_1', 'Pt_ID1', 'angle']]\n",
    "    \n",
    "    # Prepare front2 join dataframe\n",
    "    front2_join = points_df2.copy()\n",
    "    front2_join['xy_2'] = [tuple(p.coords[0]) for p in front2_join.geometry]\n",
    "    front2_join['Pt_ID2'] = np.arange(len(front2_join))\n",
    "    front2_join = front2_join[['xy_2', 'Pt_ID2', 'angle2']]\n",
    "    \n",
    "    # Calculate azimuths for trailing direction\n",
    "    azimuth_data = calculate_azimuths(trailing_result.geometry.values)\n",
    "    \n",
    "    # Add azimuth data to trailing result\n",
    "    trailing_result['spreadAZ'] = azimuth_data['spread_azimuth_trailing']\n",
    "    trailing_result['spreadAz180'] = azimuth_data['spread_az180_trailing']\n",
    "    \n",
    "    # Prepare for joining\n",
    "    trailing_result['xy1'] = [tuple(coord) for coord in azimuth_data['start_coords']]\n",
    "    trailing_result['xy2'] = [tuple(coord) for coord in azimuth_data['end_coords']]\n",
    "    \n",
    "    # Join data for trailing\n",
    "    print('Joining trailing with fire front data...')\n",
    "    trailing_result = trailing_result.merge(front1_join, how='left', left_on='xy1', right_on='xy_1')\n",
    "    trailing_result = trailing_result.merge(front2_join, how='left', left_on='xy2', right_on='xy_2')\n",
    "    \n",
    "    # Calculate normalized angle values (-180 to 180)\n",
    "    trailing_result['Front1Az180'] = np.where(trailing_result['angle'] > 180, \n",
    "                                     trailing_result['angle'] - 360, \n",
    "                                     trailing_result['angle'])\n",
    "    trailing_result['Front2Az180'] = np.where(trailing_result['angle2'] > 180, \n",
    "                                     trailing_result['angle2'] - 360, \n",
    "                                     trailing_result['angle2'])\n",
    "    \n",
    "    # Calculate angle differences for trailing\n",
    "    trailing_result['angle_diff1'] = np.abs(trailing_result['spreadAz180'] - trailing_result['Front1Az180'])\n",
    "    trailing_result['angle_diff2'] = np.abs(trailing_result['spreadAz180'] - trailing_result['Front2Az180'])\n",
    "    \n",
    "    # Apply angle filtering for trailing\n",
    "    print(\"Filtering trailing lines by angle criteria...\")\n",
    "    before_count = len(trailing_result)\n",
    "    trailing_result = trailing_result[(trailing_result.angle_diff1 > 60) & (trailing_result.angle_diff1 < 120)]\n",
    "    trailing_result = trailing_result[(trailing_result.angle_diff2 > 60) & (trailing_result.angle_diff2 < 120)]\n",
    "    after_count = len(trailing_result)\n",
    "    print(f\"Kept {after_count} of {before_count} lines after angle filtering\")\n",
    "    \n",
    "    # Filter out trailing lines that intersect with fire front lines\n",
    "    print(\"Filtering trailing lines that intersect with fire fronts...\")\n",
    "    valid_indices = []\n",
    "    \n",
    "    # Create a combined front line for faster intersection checking\n",
    "    from shapely.ops import unary_union\n",
    "    if hasattr(front1_line, '__iter__') and not hasattr(front1_line, 'geom_type'):\n",
    "        front1_line = unary_union(list(front1_line))\n",
    "    if hasattr(front2_line, '__iter__') and not hasattr(front2_line, 'geom_type'):\n",
    "        front2_line = unary_union(list(front2_line))\n",
    "    combined_fronts = unary_union([front1_line, front2_line])\n",
    "    \n",
    "    # Process trailing in batches to avoid memory issues with large datasets\n",
    "    batch_size = 100000\n",
    "    total_rows = len(trailing_result)\n",
    "    \n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch_end = min(i + batch_size, total_rows)\n",
    "        print(f\"Processing trailing batch {i}-{batch_end} of {total_rows}...\")\n",
    "        \n",
    "        # Check intersections with combined fronts\n",
    "        for idx, line in enumerate(trailing_result.iloc[i:batch_end].geometry):\n",
    "            # We want a proper crossing, not just touching at endpoints\n",
    "            start_point = line.coords[0]\n",
    "            end_point = line.coords[-1]\n",
    "                \n",
    "            # Create buffered endpoints\n",
    "            from shapely.geometry import Point\n",
    "            start_buffer = Point(start_point).buffer(0.5)\n",
    "            end_buffer = Point(end_point).buffer(0.5)\n",
    "            \n",
    "            # Check if line crosses front lines (excluding endpoints)\n",
    "            intersection = line.intersection(combined_fronts)\n",
    "            if intersection.is_empty or (\n",
    "                intersection.geom_type in ['Point', 'MultiPoint'] and \n",
    "                (start_buffer.contains(intersection) or end_buffer.contains(intersection))\n",
    "            ):\n",
    "                valid_indices.append(i + idx)\n",
    "    \n",
    "    # Apply the filter for trailing\n",
    "    if valid_indices:\n",
    "        trailing_result = trailing_result.iloc[valid_indices]\n",
    "        print(f\"Kept {len(trailing_result)} non-intersecting trailing lines after filtering\")\n",
    "    else:\n",
    "        print(\"Warning: All trailing lines intersect with fire fronts, no valid lines remain\")\n",
    "        # Use empty DataFrame for trailing to avoid errors in subsequent steps\n",
    "        trailing_result = gpd.GeoDataFrame(columns=trailing_result.columns, geometry='geometry', crs=trailing_result.crs)\n",
    "    \n",
    "    # Verify we still have data for all front2 points in trailing\n",
    "    covered_pts = set(trailing_result['Pt_ID2'].unique())\n",
    "    all_pts = set(range(len(points_df2)))\n",
    "    missing_pts = all_pts - covered_pts\n",
    "    if missing_pts:\n",
    "        print(f\"Warning: {len(missing_pts)} front2 points have no valid trailing lines after filtering\")\n",
    "    \n",
    "    # Get shortest line for each point in front2 (Pt_ID2) for trailing\n",
    "    trailing_result = trailing_result.loc[trailing_result.groupby('Pt_ID2')['length_m'].nsmallest(1).index.get_level_values(1)]\n",
    "    \n",
    "    # Clean up trailing result\n",
    "    trailing_result = trailing_result.drop(['xy1', 'xy2', 'xy_1', 'xy_2'], axis=1)\n",
    "    \n",
    "    # Store trailing result\n",
    "    results['trailing'] = trailing_result\n",
    "    \n",
    "    # Process leading direction\n",
    "    print('Processing leading to trailing spread lines...')\n",
    "    \n",
    "    # Create lines between all combinations of points (direction from points2 to points1)\n",
    "    geom = [LineString([p2, p1]) for p1, p2 in itertools.product(geom1, geom2)]\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    leading_result = gpd.GeoDataFrame({'geometry': geom}, crs=\"EPSG:26914\")\n",
    "    leading_result['length_m'] = leading_result.length\n",
    "    leading_result['direction'] = \"leading\"  # Add direction identifier\n",
    "    print(f'Created {len(leading_result)} leading lines')\n",
    "    \n",
    "    # Calculate azimuths for leading direction\n",
    "    azimuth_data = calculate_azimuths(leading_result.geometry.values)\n",
    "    \n",
    "    # Add azimuth data to leading result\n",
    "    leading_result['spreadAZ'] = azimuth_data['spread_azimuth_leading']\n",
    "    leading_result['spreadAz180'] = azimuth_data['spread_az180_leading']\n",
    "    \n",
    "    # Prepare for joining\n",
    "    leading_result['xy1'] = [tuple(coord) for coord in azimuth_data['start_coords']]\n",
    "    leading_result['xy2'] = [tuple(coord) for coord in azimuth_data['end_coords']]\n",
    "    \n",
    "    # Join data for leading\n",
    "    print('Joining leading with fire front data...')\n",
    "    leading_result = leading_result.merge(front2_join, how='left', left_on='xy1', right_on='xy_2')\n",
    "    leading_result = leading_result.merge(front1_join, how='left', left_on='xy2', right_on='xy_1')\n",
    "    \n",
    "    # Calculate normalized angle values (-180 to 180)\n",
    "    leading_result['Front1Az180'] = np.where(leading_result['angle'] > 180, \n",
    "                                    leading_result['angle'] - 360, \n",
    "                                    leading_result['angle'])\n",
    "    leading_result['Front2Az180'] = np.where(leading_result['angle2'] > 180, \n",
    "                                    leading_result['angle2'] - 360, \n",
    "                                    leading_result['angle2'])\n",
    "    \n",
    "    # Calculate angle differences for leading\n",
    "    leading_result['angle_diff1'] = np.abs(leading_result['spreadAz180'] - leading_result['Front2Az180'])\n",
    "    leading_result['angle_diff2'] = np.abs(leading_result['spreadAz180'] - leading_result['Front1Az180'])\n",
    "    \n",
    "    # Apply angle filtering for leading\n",
    "    print(\"Filtering leading lines by angle criteria...\")\n",
    "    before_count = len(leading_result)\n",
    "    leading_result = leading_result[(leading_result.angle_diff1 > 60) & (leading_result.angle_diff1 < 120)]\n",
    "    leading_result = leading_result[(leading_result.angle_diff2 > 60) & (leading_result.angle_diff2 < 120)]\n",
    "    after_count = len(leading_result)\n",
    "    print(f\"Kept {after_count} of {before_count} lines after angle filtering\")\n",
    "    \n",
    "    # Filter out leading lines that intersect with fire front lines\n",
    "    print(\"Filtering leading lines that intersect with fire fronts...\")\n",
    "    valid_indices = []\n",
    "    \n",
    "    # Process leading in batches to avoid memory issues with large datasets\n",
    "    batch_size = 100000\n",
    "    total_rows = len(leading_result)\n",
    "    \n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        batch_end = min(i + batch_size, total_rows)\n",
    "        print(f\"Processing leading batch {i}-{batch_end} of {total_rows}...\")\n",
    "        \n",
    "        # Check intersections with combined fronts\n",
    "        for idx, line in enumerate(leading_result.iloc[i:batch_end].geometry):\n",
    "            # We want a proper crossing, not just touching at endpoints\n",
    "            start_point = line.coords[0]\n",
    "            end_point = line.coords[-1]\n",
    "                \n",
    "            # Create buffered endpoints\n",
    "            from shapely.geometry import Point\n",
    "            start_buffer = Point(start_point).buffer(0.5)\n",
    "            end_buffer = Point(end_point).buffer(0.5)\n",
    "            \n",
    "            # Check if line crosses front lines (excluding endpoints)\n",
    "            intersection = line.intersection(combined_fronts)\n",
    "            if intersection.is_empty or (\n",
    "                intersection.geom_type in ['Point', 'MultiPoint'] and \n",
    "                (start_buffer.contains(intersection) or end_buffer.contains(intersection))\n",
    "            ):\n",
    "                valid_indices.append(i + idx)\n",
    "    \n",
    "    # Apply the filter for leading\n",
    "    if valid_indices:\n",
    "        leading_result = leading_result.iloc[valid_indices]\n",
    "        print(f\"Kept {len(leading_result)} non-intersecting leading lines after filtering\")\n",
    "    else:\n",
    "        print(\"Warning: All leading lines intersect with fire fronts, no valid lines remain\")\n",
    "        leading_result = gpd.GeoDataFrame(columns=leading_result.columns, geometry='geometry', crs=leading_result.crs)\n",
    "    \n",
    "    # Verify we still have data for all front1 points in leading\n",
    "    covered_pts = set(leading_result['Pt_ID1'].unique())\n",
    "    all_pts = set(range(len(points_df1)))\n",
    "    missing_pts = all_pts - covered_pts\n",
    "    if missing_pts:\n",
    "        print(f\"Warning: {len(missing_pts)} front1 points have no valid leading lines after filtering\")\n",
    "    \n",
    "    # Get shortest line for each point in front1 (Pt_ID1) for leading\n",
    "    leading_result = leading_result.loc[leading_result.groupby('Pt_ID1')['length_m'].nsmallest(1).index.get_level_values(1)]\n",
    "    \n",
    "    # Clean up leading result\n",
    "    leading_result = leading_result.drop(['xy1', 'xy2', 'xy_1', 'xy_2'], axis=1)\n",
    "    \n",
    "    # Store leading result\n",
    "    results['leading'] = leading_result\n",
    "    \n",
    "    # Combine results for output\n",
    "    if output_path:\n",
    "        combined_results = pd.concat([results['trailing'], results['leading']], ignore_index=True)\n",
    "        print(f'Combined {len(combined_results)} total spread lines')\n",
    "        print(f'Writing combined results to {output_path}')\n",
    "        combined_results.to_file(output_path)\n",
    "    \n",
    "    # Report counts\n",
    "    print(f'Processed {len(results[\"trailing\"])} trailing lines and {len(results[\"leading\"])} leading lines')\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Load your points data\n",
    "front1_points = gpd.read_file('./Insert Points1') # Trailing front points \n",
    "print(\"Loaded Front1 points\")\n",
    "\n",
    "front2_points = gpd.read_file('./Insert Points2') # Leading front points \n",
    "front2_points = front2_points.rename(columns={\"angle\": \"angle2\"}) # angle changed to angle2 for leading points\n",
    "print(\"Loaded Front2 points\")\n",
    "\n",
    "# Load fire front polylines - these are required\n",
    "front1_lines = gpd.read_file('./Insert Trailing Front Polylines1') # Trailing front polylines \n",
    "front1_line = front1_lines.geometry.unary_union\n",
    "print(\"Loaded Front1 line geometry\")\n",
    "\n",
    "front2_lines = gpd.read_file('./Insert Trailing Front Polylines2') # Leading front polylines\n",
    "front2_line = front2_lines.geometry.unary_union\n",
    "print(\"Loaded Front2 line geometry\")\n",
    "\n",
    "# Process in both directions and get results\n",
    "output_path = './FrontX_to_FrontX_spreadlines.gpkg' # Output file\n",
    "\n",
    "# Run algorithm\n",
    "results = process_spread_lines(\n",
    "    front1_points, \n",
    "    front2_points, \n",
    "    front1_line, \n",
    "    front2_line, \n",
    "    output_path=output_path\n",
    ")\n",
    "\n",
    "trailing_lines = results['trailing']\n",
    "leading_lines = results['leading']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
